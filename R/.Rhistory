#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('ntrue','error','AvgDistance','overlapping')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=6
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-6:-7], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxTrue = max(ntrue), minTrue=min(ntrue),
maxError=max(error), minError=min(error), maxDispers = max(AvgDistance),
minDispers = min(AvgDistance), maxOvlap=max(overlapping), minOvlap = min(overlapping))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,12])
write.csv(clusterData, 'clustersR.csv')
## -------------------------------------------------------------------------
##### Saving clusters data #####
write.csv(clusterData[, c('img','Clusters')], 'clustersR.csv')
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=10
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-6:-7], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxTrue = max(ntrue), minTrue=min(ntrue),
maxError=max(error), minError=min(error), maxDispers = max(AvgDistance),
minDispers = min(AvgDistance), maxOvlap=max(overlapping), minOvlap = min(overlapping))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,12])
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-6:-7], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxTrue = max(ntrue), minTrue=min(ntrue),
maxError=max(error), minError=min(error), maxDispers = max(AvgDistance),
minDispers = min(AvgDistance), maxOvlap=max(overlapping), minOvlap = min(overlapping))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,12])
## Cluster# 1:
# Predicition error level: High (positive error)
# Ground_truth: High (ntrue>50)
# Overlapping: High (>20)
# Dispersion: Medium (median AvrgDistance = 152)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "14",]
# Features relevant for k-means clustering:
clusterData = testData[c('median','error','AvgDistance','overlapping')]
# Features relevant for k-means clustering:
clusterData = testData[c('mean','error','AvgDistance','overlapping')]
# Features relevant for k-means clustering:
clusterData = testData[c('mean','error','AvgDistance','overlapping')]
testData=read.csv("test_r",stringsAsFactors = FALSE)
str(testData)
head(testData)
summary(testData)
#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('mean','error','AvgDistance','overlapping')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-6:-7], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxTrue = max(ntrue), minTrue=min(ntrue),
maxError=max(error), minError=min(error), maxDispers = max(AvgDistance),
minDispers = min(AvgDistance), maxOvlap=max(overlapping), minOvlap = min(overlapping))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,12])
aggregate(clusterData[,-6:-7], by = list(clusterData$Clusters), median)
## Cluster# 1:
# Predicition error level: High (positive error)
# Ground_truth: High (ntrue>50)
# Overlapping: High (>20)
# Dispersion: Medium (median AvrgDistance = 152)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "14",]
## Cluster# 2:
# Predicition error level: Low (combination of positive and negative errors)
# Ground_truth: Low (ntrue<50)
# Overlapping: Low (20<)
# Dispersion: Low (AvrgDistance < 142)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "6",]
## Cluster# 5:
# Predicition error level: High (positive errors)
# Ground_truth: High (ntrue>35)
# Overlapping: Low (<20)
# Dispersion: Medium (median AvrgDistance = 164)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "12",]
## Cluster# 1:
# Predicition error level: High (positive error)
# Ground_truth: High (ntrue>50)
# Overlapping: High (>20)
# Dispersion: Medium (median AvrgDistance = 152)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "5",]
## Cluster# 1:
# Predicition error level: High (positive error)
# Ground_truth: High (ntrue>50)
# Overlapping: High (>20)
# Dispersion: Medium (median AvrgDistance = 152)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "15",]
# Features relevant for k-means clustering:
clusterData = testData[c('mean','error','AvgDistance','ntrue','overlapping')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-6:-7], by = list(clusterData$Clusters), median)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxTrue = max(ntrue), minTrue=min(ntrue),
maxError=max(error), minError=min(error), maxDispers = max(AvgDistance),
minDispers = min(AvgDistance), maxOvlap=max(overlapping), minOvlap = min(overlapping))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,12])
## Cluster# 2:
# Predicition error level: Low (combination of positive and negative errors)
# Ground_truth: Low (ntrue<50)
# Overlapping: Low (20<)
# Dispersion: Low (AvrgDistance < 142)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "6",]
## Cluster# 2:
# Predicition error level: Low (combination of positive and negative errors)
# Ground_truth: Low (ntrue<50)
# Overlapping: Low (20<)
# Dispersion: Low (AvrgDistance < 142)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "9",]
## Cluster# 2:
# Predicition error level: Low (combination of positive and negative errors)
# Ground_truth: Low (ntrue<50)
# Overlapping: Low (20<)
# Dispersion: Low (AvrgDistance < 142)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "14",]
## Cluster# 2:
# Predicition error level: Low (combination of positive and negative errors)
# Ground_truth: Low (ntrue<50)
# Overlapping: Low (20<)
# Dispersion: Low (AvrgDistance < 142)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "1",]
## Cluster# 2:
# Predicition error level: Low (combination of positive and negative errors)
# Ground_truth: Low (ntrue<50)
# Overlapping: Low (20<)
# Dispersion: Low (AvrgDistance < 142)
#It is not exclusive of an specific camera (very important)
clusterData[clusterData$Clusters == "15",]
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','AvgDistance','bright')]
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','bright','AvgDistance')]
testData=read.csv("test_r",stringsAsFactors = FALSE)
str(testData)
head(testData)
summary(testData)
#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','bright','AvgDistance')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
clusterData %>%
group_by(Clusters) %>% summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
library(dplyr)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,12])
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
## Cluster# 1:
clusterData[clusterData$Clusters == "14",]
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
## Clusters# 6 and 9:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
## Cluster# 15:
clusterData[clusterData$Clusters == "15",]
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-6:-7],2,var))
for (i in 2:20) Intra[i] <- sum(kmeans(clusterData[,-6:-7], centers=i)$withinss)
plot(1:20, Intra, type="b", xlab="Number of Clusters", ylab="Mean distance to centroids")
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-7:-8],2,var))
for (i in 2:20) Intra[i] <- sum(kmeans(clusterData[,-7:-8], centers=i)$withinss)
plot(1:20, Intra, type="b", xlab="Number of Clusters", ylab="Mean distance to centroids")
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=10
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 14:
clusterData[clusterData$Clusters == "14",]
# Let´s see clusters features:
table(clusterData$Clusters)
## Clusters# 6:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 14:
clusterData[clusterData$Clusters == "14",]
## Clusters# 6:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
## Cluster# 15:
clusterData[clusterData$Clusters == "15",]
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-7:-8],2,var))
for (i in 2:20) Intra[i] <- sum(kmeans(clusterData[,-7:-8], centers=i)$withinss)
plot(1:20, Intra, type="b", xlab="Number of Clusters", ylab="Mean distance to centroids")
## -------------------------------------------------------------------------
##### Saving clusters data #####
write.csv(clusterData[, c('img','Clusters')], 'clustersR.csv')
library(dplyr)
setwd("./")
testData=read.csv("test_r",stringsAsFactors = FALSE)
str(testData)
head(testData)
summary(testData)
#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','bright','AvgDistance')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 14:
clusterData[clusterData$Clusters == "14",]
## Clusters# 6:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
## Cluster# 15:
clusterData[clusterData$Clusters == "15",]
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-7:-8],2,var))
for (i in 2:20) Intra[i] <- sum(kmeans(clusterData[,-7:-8], centers=i)$withinss)
plot(1:20, Intra, type="b", xlab="Number of Clusters", ylab="Mean distance to centroids")
## -------------------------------------------------------------------------
##### Saving clusters data #####
write.csv(clusterData[, c('img','Clusters')], 'clustersR.csv')
## -------------------------------------------------------------------------
## -------------------------------------------------------------------------
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
library(dplyr)
testData=read.csv("test_r",stringsAsFactors = FALSE)
setwd("./")
str(testData)
head(testData)
summary(testData)
#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','bright','AvgDistance')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 14:
clusterData[clusterData$Clusters == "14",]
## Clusters# 6:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
## Cluster# 15:
clusterData[clusterData$Clusters == "15",]
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-7:-8],2,var))
library(dplyr)
setwd("./")
testData=read.csv("test_r",stringsAsFactors = FALSE)
str(testData)
head(testData)
summary(testData)
#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','bright','AvgDistance')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 14:
clusterData[clusterData$Clusters == "14",]
## Clusters# 6:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
## Cluster# 15:
clusterData[clusterData$Clusters == "15",]
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-7:-8],2,var))
for (i in 2:20) Intra[i] <- sum(kmeans(clusterData[,-7:-8], centers=i)$withinss)
plot(1:20, Intra, type="b", xlab="Number of Clusters", ylab="Mean distance to centroids")
## -------------------------------------------------------------------------
##### Saving clusters data #####
write.csv(clusterData[, c('img','Clusters')], 'clustersR.csv')
## -------------------------------------------------------------------------
## -------------------------------------------------------------------------
library(dplyr)
setwd("./")
testData=read.csv("test_r",stringsAsFactors = FALSE)
str(testData)
head(testData)
summary(testData)
#testData$cam = as.factor(testData$cam)
testData$error_th10 = as.factor(testData$error_th10)
# Features relevant for k-means clustering:
clusterData = testData[c('error','ntrue','overlapping','bright','AvgDistance')]
# Variables normalization:
clusterDataScaled=scale(clusterData)
# Number of clusters (based on "Elbow method", see ANNEX below)
NUM_CLUSTERS=15
# k-means tends to converge to local minimums, being highly sensitive to initialization conditions.
set.seed(1234)
Model=kmeans(clusterDataScaled,NUM_CLUSTERS)
clusterData$Clusters=Model$cluster
clusterData$img =testData$img
clusterData$cam =testData$cam
# Let´s see clusters features:
table(clusterData$Clusters)
aggregate(clusterData[,-7:-8], by = list(clusterData$Clusters), median)
clusterData %>%
group_by(Clusters) %>%
summarise(maxError=max(error), minError=min(error), maxTrue = max(ntrue), minTrue=min(ntrue),
maxOvlap=max(overlapping), minOvlap = min(overlapping), maxBright=max(bright),
minBright = min(bright),maxDispers = max(AvgDistance), minDispers = min(AvgDistance))
# And let´s see the prediction error levels split by cluster:
table(clusterData$Clusters,testData[,13])
## Cluster# 14:
clusterData[clusterData$Clusters == "14",]
## Clusters# 6:
clusterData[clusterData$Clusters == "6",]
## Cluster# 9:
clusterData[clusterData$Clusters == "9",]
## Cluster# 15:
clusterData[clusterData$Clusters == "15",]
## Cluster# 1:
clusterData[clusterData$Clusters == "1",]
Intra <- (nrow(clusterData[,-6:-7])-1)*sum(apply(clusterData[,-7:-8],2,var))
for (i in 2:20) Intra[i] <- sum(kmeans(clusterData[,-7:-8], centers=i)$withinss)
plot(1:20, Intra, type="b", xlab="Number of Clusters", ylab="Mean distance to centroids")
## -------------------------------------------------------------------------
##### Saving clusters data #####
write.csv(clusterData[, c('img','Clusters')], 'clustersR.csv')
## -------------------------------------------------------------------------
